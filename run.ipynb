{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Tuple, List, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
    "from langchain.docstore.document import Document \n",
    "'''part of the LangChain library and is used to represent a piece of text or document data along with its metadata. \n",
    "It is a common data structure used throughout the LangChain library for storing and processing text data.\n",
    "In your code, you are using the Document class to create new Document objects from the preprocessed text data. \n",
    "Specifically, you are creating a dictionary with the page_content (the actual text content) and metadata (additional information about the text, such as the source), \n",
    "and then creating a Document object using that dictionary.'''\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from py2neo import Graph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"bolt://localhost:7687\"\n",
    "graph = Neo4jGraph(url=URI, username=\"neo4j\", password=\"password\")\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"insta.txt\")\n",
    "raw_documents = loader.load()\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_documents[:3])\n",
    "\n",
    "# Preprocess the documents to convert lists to tuples\n",
    "'''we create a new dictionary with the page_content and metadata keys, where the metadata key has a nested dictionary with the source key. \n",
    "We convert the source value to a tuple if it's a list, and then create a new Document object from this dictionary using the Document constructor.\n",
    "This way, we avoid using the non-existent to_dict and from_dict methods and create a new Document object with the desired structure.\n",
    "With this modification, the code should run without the AttributeError: 'Document' object has no attribute 'to_dict' error.'''\n",
    "preprocessed_documents = []\n",
    "for doc in documents:\n",
    "    data = {\n",
    "        \"page_content\": doc.page_content,\n",
    "        \"metadata\": {\n",
    "            \"source\": tuple(doc.metadata[\"source\"]) if isinstance(doc.metadata[\"source\"], list) else doc.metadata[\"source\"]\n",
    "        }\n",
    "    }\n",
    "    preprocessed_documents.append(Document(**data))\n",
    "\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(preprocessed_documents)\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Settings.embed_model = HuggingFaceEmbedding(\n",
    "#     model_name=\"BAAI/bge-small-en-v1.5\"\n",
    "# )\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    username='neo4j',\n",
    "    password='password',\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "# Retriever\n",
    "\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "graph.run(\n",
    "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\"\n",
    ")\n",
    "\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "def showGraph(graph_documents):\n",
    "    net = Network(height=\"800px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "    \n",
    "    nodes = graph_documents[0].nodes\n",
    "    relationships = graph_documents[0].relationships\n",
    "    \n",
    "    for node in nodes:\n",
    "        net.add_node(node.id, label=node.id, title=str(node.type), color=\"skyblue\")\n",
    "    \n",
    "    for relationship in relationships:\n",
    "        net.add_edge(relationship.source.id, relationship.target.id, title=relationship.type, color=\"gray\", arrows=\"to\")\n",
    "    \n",
    "    net.repulsion()\n",
    "    \n",
    "    # Generate HTML file\n",
    "    net.write_html(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "showGraph(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\n",
      "\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    AIMessage(\n",
    "        content=\"tell me about instagram\"\n",
    "    )\n",
    "]\n",
    "\n",
    "chat_model_response = llm.invoke(messages)\n",
    "print(chat_model_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
